# 2. Базовые инструменты для профилирования

В таблице ниже указаны базовые инструменты профилирования python-приложений. Они просты в использовании, подходят для начального анализа производительности и памяти.

| Инструмент      | Краткое пояснение                                                                                |
| --------------- | ------------------------------------------------------------------------------------------------ |
| timeit          | Измеряет время выполнения небольших фрагментов кода, полезен для микробенчмаркинга.              |
| cProfile        | Встроенный профилировщик Python, собирает статистику по времени и количеству вызовов функций.    |
| dis             | Модуль для дизассемблирования байткода Python, помогает понять, как интерпретатор выполняет код. |
| memory_profiler | Отслеживает использование памяти по строкам кода.                                                |
| tracemalloc     | Встроенный инструмент для отслеживания выделения памяти и поиска утечек.                         |

## timeit

[https://docs.python.org/3/library/timeit.html](https://docs.python.org/3/library/timeit.html)

`timeit` - это встроенный модуль Python для точного измерения времени выполнения небольших фрагментов кода (обычно одной или нескольких строк). Он предназначен для микробенчмаркинга и позволяет избежать ошибок, связанных с влиянием кэширования, фоновых процессов и особенностей работы интерпретатора.

Использовать timeit следует, когда надо:

- сравнить производительность разных реализаций одной и той же функции или алгоритма;

- оценить скорость выполнения отдельных операций (например, list vs. set);

- получить объективные данные о времени работы кода без влияния внешних факторов;

- измерить время выполнения кода, где важна точность до микросекунд.

### Примеры использования timeit

**Через командную строку**

```Shell
python -m timeit "sum(range(1000))"
# 50000 loops, best of 5: 9.46 usec per loop
```

По умолчанию команда выполнит выражение несколько тысяч раз и выведет среднее время.

**Внутри Python-скрипта**

```Python
import timeit

result = timeit.timeit("sum(range(1000))", number=10000)
print(result) # 0.09725100000014208
```

`number` - сколько раз повторить выполнение кода.

Можно передавать код как строку или использовать функцию через аргумент `stmt`.

**С помощью магических команд Jupyter/IPython**

```Python
%timeit sum(range(1000))
# 36 µs ± 12 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)
```

Удобно для интерактивной работы: автоматически подбирает количество повторов и показывает среднее и стандартное отклонение.

### Советы по использованию timeit

- для простых выражений используйте строку, для сложных - определяйте функцию и передавайте её в `timeit`;

- избегайте измерения кода, который зависит от внешних ресурсов (файловая система, сеть);

- для кода с побочными эффектами (например, изменение глобальных переменных) используйте отдельные тестовые функции;

- для сравнения нескольких вариантов используйте одинаковые условия запуска.

Пример сравнения двух способов сложения чисел

```Python
import timeit

def sum_for():
    total = 0
    for i in range(1000):
        total += i
    return total

def sum_builtin():
    return sum(range(1000))

print("for-loop:", timeit.timeit(sum_for, number=10000))
print("builtin sum:", timeit.timeit(sum_builtin, number=10000))

# for-loop: 0.24309808300040459
# builtin sum: 0.09503229199981433
```

Так можно объективно сравнить производительность разных подходов.

`timeit` не стоит использовать:

- для профилирования больших программ или анализа по строкам (лучше использовать профилировщики);

- для кода с длительным временем выполнения (timeit рассчитан на быстрые операции).

`timeit` - лучший выбор для быстрой и точной оценки производительности небольших фрагментов кода, особенно когда нужно сравнить разные реализации алгоритмов или операций.

## cProfile

[https://docs.python.org/3/library/profile.html](https://docs.python.org/3/library/profile.html)

`cProfile` - это встроенный профилировщик Python, который позволяет измерять время выполнения каждой функции в программе и количество вызовов этих функций. Он помогает выявить узкие места и понять, где код тратит больше всего времени.

Использовать cProfile следует, когда надо:

- проанализировать производительность всего скрипта или большого фрагмента кода;
- узнать, какие функции вызываются чаще всего и где тратится основное время исполнения;
- проверить узкие места или неэффективные участки в сложных проектах;
- сравнить влияние оптимизаций на производительность.

### Примеры использования cProfile

**Профилирование всего скрипта через командную строку**

```Shell
python -m cProfile src/base-profiling/03_cprofile.py

# 9443 function calls (9411 primitive calls) in 0.037 seconds
#
# Ordered by: cumulative time
#
#    ncalls  tottime  percall  cumtime  percall filename:lineno(function)
#      3/1    0.000    0.000    0.037    0.037 {built-in method builtins.exec}
#        1    0.000    0.000    0.037    0.037 03_cprofile.py:1(<module>)
#        1    0.000    0.000    0.029    0.029 03_cprofile.py:16(main)
#        1    0.028    0.028    0.029    0.029 03_cprofile.py:4(bubble_sort)
#    ...
```

Выведет статистику по всем функциям: сколько раз вызваны, сколько времени заняли, сколько времени в сумме и т.д.

Или с опцией сортировки:

```Shell
python -m cProfile -s time src/base-profiling/03_cprofile.py

# 9444 function calls (9412 primitive calls) in 0.037 seconds
#
# Ordered by: internal time
#
#   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
#        1    0.028    0.028    0.029    0.029 03_cprofile.py:4(bubble_sort)
#        4    0.005    0.001    0.005    0.001 {built-in method _imp.create_dynamic}
#        2    0.000    0.000    0.000    0.000 {built-in method _io.open_code}
#     1000    0.000    0.000    0.001    0.000 random.py:291(randrange)
#    ...
```

Сортирует результаты по времени выполнения функций, чтобы быстрее найти самые дорогие.

**Использование внутри Python-кода**

```Python
import cProfile
import random
import time


data = [random.randint(1, 1000) for _ in range(1000)]


def slow_function():
    arr = data.copy()
    n = len(arr)

    for i in range(n):
        for j in range(0, n - i - 1):
            if arr[j] > arr[j + 1]:
                temp = arr[j]
                arr[j] = arr[j + 1]
                arr[j + 1] = temp

                _ = [x for x in range(10)]
                _ = sum(range(100))

                time.sleep(0.00001)

    return arr


def main():
    cProfile.run("slow_function()")


if __name__ == "__main__":
    main()
```

```Shell
python src/base-profiling/04_cprofile.py

# 515558 function calls in 4.603 seconds
#
# Ordered by: standard name
#
#   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
#        1    0.174    0.174    4.603    4.603 04_cprofile.py:29(slow_function)
#        1    0.000    0.000    4.603    4.603 <string>:1(<module>)
#        1    0.000    0.000    4.603    4.603 {built-in method builtins.exec}
#        1    0.000    0.000    0.000    0.000 {built-in method builtins.len}
#   257776    0.105    0.000    0.105    0.000 {built-in method builtins.sum}
#   257776    4.324    0.000    4.324    0.000 {built-in method time.sleep}
#        1    0.000    0.000    0.000    0.000 {method 'copy' of 'list' objects}
#        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
```

Удобно для профилирования отдельных функций или частей программы.

Можно сохранить результаты для последующего анализа:

```Python
import cProfile
import random
import time
import pstats


data = [random.randint(1, 1000) for _ in range(1000)]


def slow_function():
    arr = data.copy()
    n = len(arr)

    for i in range(n):
        for j in range(0, n - i - 1):
            if arr[j] > arr[j + 1]:
                temp = arr[j]
                arr[j] = arr[j + 1]
                arr[j + 1] = temp

                _ = [x for x in range(10)]
                _ = sum(range(100))

                time.sleep(0.00001)

    return arr


def main():
    cProfile.run("slow_function()", "profile_results")
    stats = pstats.Stats("profile_results")
    stats.sort_stats("time").print_stats(10)


if __name__ == "__main__":
    main()
```

```Shell
python src/base-profiling/05_cprofile.py

# Tue Jul 15 19:24:17 2025    profile_results
#
#         521462 function calls in 4.637 seconds
#
#   Ordered by: internal time
#
#   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
#   260728    4.353    0.000    4.353    0.000 {built-in method time.sleep}
#        1    0.178    0.178    4.637    4.637 05_cprofile.py:10(slow_function)
#   260728    0.106    0.000    0.106    0.000 {built-in method builtins.sum}
#        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
#        1    0.000    0.000    4.637    4.637 <string>:1(<module>)
#        1    0.000    0.000    4.637    4.637 {built-in method builtins.exec}
#        1    0.000    0.000    0.000    0.000 {method 'copy' of 'list' objects}
#        1    0.000    0.000    0.000    0.000 {built-in method builtins.len}
```

Позволяет анализировать результаты позже, сортировать по разным метрикам (время, количество вызовов и др.). **pstats** - это встроенный в Python модуль для анализа и обработки результатов профилирования, собранных с помощью профилировщиков вроде `cProfile`.

Возможно использовать контекстный менеджер для профилирования конкретного участка кода:

```Python
import cProfile
import random
import time
import pstats


data = [random.randint(1, 1000) for _ in range(1000)]


def slow_function():
    arr = data.copy()
    n = len(arr)

    for i in range(n):
        for j in range(0, n - i - 1):
            if arr[j] > arr[j + 1]:
                temp = arr[j]
                arr[j] = arr[j + 1]
                arr[j + 1] = temp

                _ = [x for x in range(10)]
                _ = sum(range(100))

                time.sleep(0.00001)

    return arr


def main():
    profiler = cProfile.Profile()
    profiler.enable()

    slow_function() # профилируемый код

    profiler.disable()
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative').print_stats(4)


if __name__ == "__main__":
    main()
```

```Shell
python src/base-profiling/06_cprofile.py

#         482692 function calls in 4.292 seconds
#
#   Ordered by: cumulative time
#   List reduced from 6 to 4 due to restriction <4>
#
#   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
#        1    0.158    0.158    4.292    4.292 06_cprofile.py:10(slow_function)
#   241344    4.037    0.000    4.037    0.000 {built-in method time.sleep}
#   241344    0.097    0.000    0.097    0.000 {built-in method builtins.sum}
#        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
```

Позволяет профилировать только нужный участок программы.

### **Как читать результаты**

В отчёте отображаются:

- `ncalls` - количество вызовов функции;
- `tottime` - чистое время выполнения функции (без учёта вызова подфункций);
- `cumtime` - суммарное время функции и всех её подфункций;
- `percall` - среднее время на вызов;
- `filename:lineno(function)` - где определена функция.

### Советы по использованию cProfile

- для визуализации результатов используйте сторонние инструменты, например, [SnakeViz](https://jiffyclub.github.io/snakeviz/);
- сначала профилируйте весь скрипт, затем - узкие места по отдельности;
- не используйте для микробенчмаркинга (лучше подходит `timeit`);
- для анализа по строкам используйте `line_profiler`.

`cProfile`не стоит использовать:

- для очень коротких фрагментов кода (лучше `timeit`);
- для анализа использования памяти (лучше `memory_profiler` или `tracemalloc`).

`cProfile` - мощный инструмент для поиска и устранения проблем с производительностью в Python-программах, особенно когда требуется анализировать сложные проекты или выявлять узкие места на уровне функций.

## dis

[https://docs.python.org/3/library/dis.html](https://docs.python.org/3/library/dis.html)

`dis` - это встроенный модуль Python для **дизассемблирования байткода**. Он позволяет увидеть, в какие низкоуровневые инструкции Python-программа преобразуется интерпретатором CPython. Это полезно для анализа производительности, глубинного понимания работы Python, а также отладки и поиска ошибок на уровне исполнения.

`dis`подходит, если нужно:

- понять, как Python исполняет определённый фрагмент кода;
- увидеть разницу в байткоде между различными реализациями одного и того же алгоритма;
- анализировать оптимизацию компилятора Python;
- искать неочевидные неэффективные конструкции (например, ненужные обращения к глобальным переменным, лишние инструкции);
- углубиться в детали работы Python для образовательных целей, написания JIT-компиляторов, отладки расширений и собственных интерпретаторов.

### Примеры использования dis

**Быстрое дизассемблирование функции**

```Python
import dis


def func(x):
    return x + 1


dis.dis(func)
```

```Shell
python src/base-profiling/07_dis.py

#  4           0 RESUME                   0
#
#  5           2 LOAD_FAST                0 (x)
#              4 LOAD_CONST               1 (1)
#              6 BINARY_OP                0 (+)
#             10 RETURN_VALUE
```

На экран будет выведен байткод для функции `func`.

**Использование из командной строки**

```Python
def func(x):
    return x + 1
```

```Shell
python -m dis src/base-profiling/08_dis.py

#  0           0 RESUME                   0
#
#  1           2 LOAD_CONST               0 (<code object func at 0x1052939e0, file "src/base-profiling/08_dis.py", line 1>)
#              4 MAKE_FUNCTION            0
#              6 STORE_NAME               0 (func)
#              8 RETURN_CONST             1 (None)
#
# Disassembly of <code object func at 0x1052939e0, file "src/base-profiling/08_dis.py", line 1>:
#  1           0 RESUME                   0
#
#  2           2 LOAD_FAST                0 (x)
#              4 LOAD_CONST               1 (1)
#              6 BINARY_OP                0 (+)
#             10 RETURN_VALUE
```

Показывает байткод для всего скрипта или всех функций класса.

### Что отображает `dis`

В результате вы увидите таблицу, где каждая строка - инструкция байткода (например, `LOAD_FAST`, `BINARY_ADD`, `RETURN_VALUE`).

Каждая строка вывода соответствует одной инструкции (opcode) байткода. В выводе обычно присутствуют следующие колонки:

- **Offset** - смещение (позиция инструкции в байткоде функции);
- **Line** - если инструкция соответствует строке исходного кода, указывается её номер;
- **Opcode Name** - название инструкции (например, `LOAD_FAST`, `BINARY_ADD`);
- **Argument** - опциональное значение аргумента инструкции (если требуется);
- **Argument Details** - подробности об аргументе (например, имя переменной, литерал) - также опциональны.

Разберём вывод dis:

```Shell
python src/base-profiling/07_dis.py

#  4           0 RESUME                   0
#
#  5           2 LOAD_FAST                0 (x)
#              4 LOAD_CONST               1 (1)
#              6 BINARY_OP                0 (+)
#             10 RETURN_VALUE
```

Этот кусок байткода показывает, что функция `func(x)` реализована максимально просто:

- она берёт аргумент `x`;
- прибавляет к нему единицу;
- и возвращает результат.

Каждая строка байткода соответствует этапу выполнения Python-операций на самом низком уровне - так, как их видит интерпретатор CPython.

| Строка (**Line**) | Сдвиг (Offset) | Инструкция (**Opcode Name**) | Аргумент (**Argument**) | Объяснение                                                                                                |
| ----------------- | -------------- | ---------------------------- | ----------------------- | --------------------------------------------------------------------------------------------------------- |
| 4                 | 0              | RESUME                       | 0                       | Служебная инструкция (с версии Python 3.11+). Служит для подготовки интерпретатора к исполнению байткода. |
| 5                 | 2              | LOAD_FAST                    | 0 (x)                   | Загрузить значение локальной переменной `x` на стек.                                                      |
| 5                 | 4              | LOAD_CONST                   | 1 (1)                   | Загрузить константу `1` на стек.                                                                          |
| 5                 | 6              | BINARY_OP                    | 0 (+)                   | Выполнить бинарную операцию сложения двух верхних значений на стеке (`x + 1`).                            |
| 5                 | 10             | RETURN_VALUE                 |                         | Вернуть результат вышестоящему коду (выход из функции).                                                   |

Интерпретация байткода:

- инструкции с префиксом `LOAD_` или `STORE_` - взаимодействуют с переменными;
- `CALL_` - вызов функции;
- `BINARY_` - бинарные операции (сложение, вычитание и т. д.);
- `RETURN_VALUE` - завершение функции;
- переходы (`JUMP`) отображают логику ветвления и циклов.

### Советы по использованию dis

- для сравнения эффективности разных подходов сначала используйте `timeit`, а затем для глубокого анализа - `dis`;
- для быстрого анализа кода функции передавайте её напрямую в `dis.dis()`;
- анализируйте отдельные выражения без создания функции через `dis.dis("выражение")`;
- если хотите дизассемблировать весь класс, передавайте класс `в dis.dis()`;
- не дизассемблируйте слишком большие объекты без необходимости.

`dis`не стоит использовать:

- для измерения времени или выявления узких мест (лучше применять `timeit` или `cProfile`);
- для профилирования памяти (лучше `memory_profiler` или `tracemalloc`);
- для анализа крупных программ - dis удобнее именно для точечного исследования функций и коротких участков кода.

`dis` делает видимым внутренний процесс исполнения Python-кода: всё, что происходит после компиляции строк исходного кода - какие инструкции сформированы, как управляется стек, какие данные используются и как происходит возврат результата. Это фундаментальный инструмент для разработчиков, которым важно залезть под капот языка.

## memory_profiler

[https://pypi.org/project/memory-profiler/](https://pypi.org/project/memory-profiler/)

`memory_profiler` - это сторонний модуль Python для **поcтроенной по строкам оценки использования памяти** во время исполнения кода. Он позволяет выявлять утечки памяти, неочевидное потребление памяти в разных участках программы, а также находить самые дорогие строки в функциях.

Использовать `memory_profiler` можно:

- когда есть подозрение, что программа расходует слишком много памяти или содержит утечку памяти;
- для мониторинга выделения памяти в отдельных функциях или по строкам кода;
- в задачах по анализу эффективности, связанных с большими объёмами данных, машинным обучением, обработкой файлов и изображений;
- если стандартные средства типа `tracemalloc` не дают подробного среза по строкам.

### Примеры использования memory_profiler

**Установка**

```Shell
pip install memory_profiler
```

**Строковое профилирование функций**

Для анализа функции требуется добавить декоратор `@profile`:

```Python
from memory_profiler import profile


@profile
def my_func():
    a = [1] * (10**6)
    b = [2] * (2 * 10**7)
    del b
    return a


if __name__ == "__main__":
    my_func()
```

```Shell
python -m memory_profiler src/base-profiling/09_memory-profiler.py

# Filename: src/base-profiling/09_memory-profiler.py
#
# Line #    Mem usage    Increment  Occurrences   Line Contents
# =============================================================
#     4     29.7 MiB     29.7 MiB           1   @profile
#     5                                         def my_func():
#     6     37.3 MiB      7.6 MiB           1       a = [1] * (10**6)
#     7    189.9 MiB    152.6 MiB           1       b = [2] * (2 * 10**7)
#     8     37.3 MiB   -152.6 MiB           1       del b
#     9     37.3 MiB      0.0 MiB           1       return a
```

В терминале появится подробный отчёт об использовании памяти на каждой строке помеченных декоратором функций.

Что означают колонки:

- **Line #** - номер строки исходного кода, который был профилирован.
- **Mem usage** - общее потребление памяти в момент выполнения этой строки (в мегабайтах).
- **Increment** - насколько увеличилось (или уменьшилось) потребление памяти относительно предыдущей строки.
- **Occurrences** - сколько раз эта строка была выполнена (обычно 1 для простых последовательных участков).
- **Line Contents** - содержимое исходного кода, соответствующее строке.

Пояснения по выводу:

- Строка 4 (`@profile`)

  - Память при входе в функцию была около 29.7 МБ. Это базовый уровень памяти перед началом выполнения тела функции.
  - Так как здесь находится только декоратор, реальных действий не происходит.

- Строка 6 (`a = * (10**6)`)

  - Память выросла с 29.7 до 37.3 МБ - это увеличение на 7.6 МБ.
  - Создаётся список `a` из миллиона элементов (из числа 1). Этот список занимал примерно 7.6 МБ дополнительной памяти.

- Строка 7 (`b = * (2 * 10**7)`)

  - Память резко увеличивается с 37.3 до 189.9 МБ - прирост на 152.6 МБ.
  - Создаётся очень большой список `b` из 20 миллионов элементов (число 2).
  - Эти данные занимают много памяти, что хорошо видно по большому увеличению.

- Строка 8 (`del b`)

  - Память возвращается обратно к 37.3 МБ - уменьшение на 152.6 МБ.
  - Переменная `b` удалена, объекты, которые она содержала, становятся доступными сборщику мусора.
  - Освобожденный объём примерно равен приросту, который был при создании списка `b`.

- Строка 9 (`return a`)
  - Память остаётся стабильной, никакого изменения не происходит.
  - Возвращается список `a`, который занимает примерно 7.6 МБ.

**Использование магии IPython/Jupyter**

Для Jupyter Notebook используется магическая команда:

```Python
%load_ext memory_profiler
%memit [выражение]
```

Результат показывает, сколько памяти использовала команда или функция.

**Мгновенный анализ с помощью mprof**

Для быстрой оценки пика выделенной памяти:

```Shell
mprof run src/base-profiling/09_memory-profiler.py
mprof plot  # Для построения графика расхода памяти во времени
```

![](assets/mprof-plot.png)

`mprof` - утилита, которая устанавливается вместе с пакетом и позволяет отслеживать динамику изменения потребления памяти на всём протяжении выполнения программы.

### Советы по использованию

- профилируйте отдельные функции, где предполагаются проблемы с памятью - это повысит скорость анализа;
- минус - встроенная пауза на каждой строке, используйте инструмент для поиска узких мест, но не для большого production-кода;
- для анализа всего скрипта используйте `mprof run`, для отдельных функций - декоратор `@profile`.

`memory_profiler` не подходит:

- для профилирования C-расширений или кода, работающего вне Python-интерпретатора;
- для программ, в которых критична скорость исполнения во время профилирования;
- при необходимости отслеживать только выделения памяти без детализации по строкам - используйте для этого `tracemalloc`.

`memory_profiler` - эффективный инструмент для получения точного отчёта о расходе памяти на уровне отдельных строк кода Python. Он помогает выявлять неожиданные утечки памяти и пишет подробные отчёты, что делает его незаменимым при тестировании и оптимизации памяти в скриптах и приложениях.

## tracemalloc

[https://docs.python.org/3/library/tracemalloc.html](https://docs.python.org/3/library/tracemalloc.html)

`tracemalloc` - это стандартный модуль Python для отслеживания выделения памяти программой на уровне строк кода. Он особенно полезен для поиска утечек памяти и анализа того, где и сколько памяти было выделено.

`tracemalloc`используют:

- если программа неожиданно разбухает в памяти и вы подозреваете утечку;
- для оптимизации расхода памяти в условиях больших данных, сложных объектов, длительных вычислений;
- когда требуется понять, какая часть кода или библиотеки отвечает за выделение памяти;
- чтобы диагностировать узкие места по памяти не только в вашем коде, но и в сторонних библиотеках.

### Примеры использования tracemalloc

**Измерение текущего и пикового использования памяти**

```Python
import tracemalloc

tracemalloc.start()

lst = [i for i in range(10**6)]

current, peak = tracemalloc.get_traced_memory()
print(f"Текущее использование памяти: {current / 1024 / 1024:.2f} МБ")
print(f"Пиковое использование памяти: {peak / 1024 / 1024:.2f} МБ")

tracemalloc.stop()
```

```Shell
python src/base-profiling/10_tracemalloc.py

# Текущее использование памяти: 38.57 МБ
# Пиковое использование памяти: 38.57 МБ
```

Этот код показывает, сколько памяти занято и какой был максимум за время отслеживания.

**Сравнение снимков состояния памяти до и после создания объекта**

```Python
import tracemalloc

tracemalloc.start()

snapshot1 = tracemalloc.take_snapshot()

data = [str(i) * 100 for i in range(100000)]

snapshot2 = tracemalloc.take_snapshot()

# Сравнить снимки, чтобы найти самые дорогие строки
top_stats = snapshot2.compare_to(snapshot1, "lineno")

print("ТОП строк по потреблению памяти:")
for stat in top_stats[:5]:
    print(stat)

tracemalloc.stop()
```

```Shell
python src/base-profiling/11_tracemalloc.py

# ТОП строк по потреблению памяти:
# src/base-profiling/11_tracemalloc.py:7: size=51.3 MiB (+51.3 MiB), count=100001 (+100001), average=538 B
# src/base-profiling/11_tracemalloc.py:5: size=400 B (+400 B), count=1 (+1), average=400 B
# Python.framework/Versions/3.12/lib/python3.12/tracemalloc.py:560: size=312 B (+312 B), count=2 (+2), average=156 B
# Python.framework/Versions/3.12/lib/python3.12/tracemalloc.py:423: size=312 B (+312 B), count=2 (+2), average=156 B
```

Используется для выявления строк кода, приведших к наибольшему приросту памяти.

Разбор вывода:

1. **`src/base-profiling/11_tracemalloc.py:7`**

- Это строка: `data = [str(i) * 100 for i in range(100000)]`
- size=51.3 MiB - вся память, ассоциированная с этой строкой кода (всего выделено).
- (+51.3 MiB) - прирост памяти с момента `snapshot1` (до этой строки).
- count=100001 - количество объектов, созданных на этой строке.
- average=538 B - средний размер одного объекта. Это и есть основной источник потребления памяти: 100 000 строк, каждая из которых содержит `str(i) * 100`.

2. **`src/base-profiling/11_tracemalloc.py:5`**

- Это строка: `snapshot1 = tracemalloc.take_snapshot()`
- Появился один объект размером 400 байт - это, вероятно, сам снимок памяти или вспомогательная структура.
- Незначительное потребление.

3. **`tracemalloc.py:560` и `tracemalloc.py:423`**

- Это внутренние строки реализации `tracemalloc` из стандартной библиотеки.
- Они показывают, что и сам модуль создаёт некоторые объекты при работе: по 2 объекта по ~150 байт.
- Это нормальное поведение механизма отслеживания - эти строки можно игнорировать (не утечка).

Как интерпретировать:

- Наибольшее потребление памяти (51.3 MiB) - в строке, где создаётся список `data`.
  Это логично: длинный список строк (`100000` строк по 100 символов) действительно потребляет много памяти.
- `tracemalloc` показывает не только сколько памяти выделилось всего, но и какие строки кода её выделили.
- Модель: `строка → размер → количество объектов → средний размер` очень удобна для оптимизации.

**Сбор статистики по файлам и строкам, анализ узких мест**

```Python
import tracemalloc

tracemalloc.start()

l1 = [i for i in range(10000)]
l2 = [i * i for i in range(10000)]
l3 = [i * i * i for i in range(10000)]

snapshot = tracemalloc.take_snapshot()
stats = snapshot.statistics("lineno")

print("Это список мест с максимальным выделением памяти:")
for stat in stats[:3]:
    print(stat)
```

```Shell
python src/base-profiling/12_tracemalloc.py

# Это список мест с максимальным выделением памяти:
# src/base-profiling/12_tracemalloc.py:7: size=395 KiB, count=9994, average=41 B
# src/base-profiling/12_tracemalloc.py:6: size=395 KiB, count=9984, average=41 B
# src/base-profiling/12_tracemalloc.py:5: size=388 KiB, count=9745, average=41 B
```

Разбор вывода:

4. **`src/base-profiling/12_tracemalloc.py:7`**

- Это строка: `l3 = [i * i * i for i in range(10000)]`
- size = 395 KiB - общий объём памяти, выделенный объектами, созданными на этой строке.
- count = 9994 - было создано почти 10 000 объектов (почти каждое выражение `i * i * i` приводит к новому `int`).
- average = 41 B - средний размер одного объекта. Это соответствует среднему размеру объекта `int` в CPython (обычно 28–48 байт).
- Это самая тяжёлая строка по памяти в этом коде, но разница с другими минимальна.

5. **`src/base-profiling/12_tracemalloc.py:6`**

- Это строка: `l2 = [i * i for i in range(10000)]`
- size = 395 KiB - столько же, сколько и строка выше, хотя результат квадратов чуть проще.
- count = 9984 - немного меньше объектов (возможно, из-за переиспользования значений, например, `0`, `1`, `4` и т.п.).
- average = 41 B - такой же средний вес одного объекта.
- Занимает практически столько же памяти, как и строка с кубами - показывает, что прогрессивность операций (`i*i` vs `i*i*i`) почти не влияет в данном случае.

6. **`src/base-profiling/12_tracemalloc.py:5`**

- Это строка: `l1 = [i for i in range(10000)]`
- size = 388 KiB - немного меньше, чем у остальных строк.
- count = 9745 - было создано меньше новых объектов, потому что значение `i` часто попадает в область кэшируемых чисел Python (`-5` до `256`). То есть переменные с этими значениями не создаются заново, а переиспользуются.
- average = 41 B - такой же средний размер для объектов, которые всё же были созданы заново.
- Это пример того, как внутренняя оптимизация CPython (аренда/кэширование int) влияет на реальное потребление памяти.

Как интерпретировать:

- Три строки, создающие списки с числами, потребляют примерно по 390–400 KiB памяти каждая.
- Примерно 10 000 объектов типа `int` создаются в каждой строке.
- Память потребляется равномерно, но немного отличается из-за встроенной оптимизации Python (переиспользование объектов).
- Самая тяжёлая строка - где вычисляются кубы (`l3`), но разница по размеру с остальными минимальна.

**Автоматический сброс пикового значения**

```Python
import tracemalloc

tracemalloc.start()

for i in range(3):
    temp = [j for j in range(100000)]
    current, peak = tracemalloc.get_traced_memory()
    print(
        f"{i=}: current={current / 1024 / 1024:.2f} МБ, peak={peak / 1024 / 1024:.2f} МБ"
    )
    tracemalloc.reset_peak()  # Сброс пика после каждой итерации
```

```Shell
python src/base-profiling/13_tracemalloc.py

# i=0: current=3.81 МБ, peak=3.81 МБ
# i=1: current=3.81 МБ, peak=7.62 МБ
# i=2: current=3.81 МБ, peak=7.62 МБ
```

Удобно для анализа последовательных операций и контроля пикового потребления памяти для каждой из них.

**Сохранение снимка в файл и его последующая загрузка**

```Python
import tracemalloc

tracemalloc.start()
lst = [i for i in range(10000)]
snapshot = tracemalloc.take_snapshot()
tracemalloc.stop()

snapshot.dump("snapshot.out")  # Сохраняем снимок
print("Снимок памяти сохранён в файл.")

snapshot_loaded = tracemalloc.Snapshot.load("snapshot.out")
print("Загруженный снимок:")
for stat in snapshot_loaded.statistics("lineno")[:3]:
    print(stat)
```

```Shell
python src/base-profiling/14_tracemalloc.py

# Снимок памяти сохранён в файл.
# Загруженный снимок:
# src/base-profiling/14_tracemalloc.py:4: size=388 KiB, count=9745, average=41 B
```

Позволяет сохранять и анализировать снимки позже или на другой машине.

### Советы по использованию

- запускайте `tracemalloc` как можно раньше, чтобы поймать все выделения памяти;
- сравнивайте снимки до и после подозрительных участков кода, чтобы локализовать источник утечек;
- для более глубокого анализа используйте разные ключи сортировки statistics: `lineno`, `filename`, `traceback`;
- используйте `tracemalloc.reset_peak()` для сброса значения максимального пика;
- после фиксации проблемы остановите профилирование, чтобы не тратить ресурсы.

`tracemalloc` не подойдёт:

- для профилирования С-расширений или кода вне интерпретатора CPython - только Python-объекты;
- если важно узнать память, занимаемую вне кучи Python (например, буферы NumPy, вложения в C-модулях).

`tracemalloc` - мощный стандартный инструмент для поиска утечек и оптимизации распределения памяти в вашем Python-коде, особенно хорошо подходит для сложных и долго живущих программ и анализа сторонних библиотек.
